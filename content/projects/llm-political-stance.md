---
date: 2024-02-20T00:00:00+01:00
draft: false
title: "LLM-based Political Stance Classification"
projectTitle: "LLM-based Political Stance Classification"
company: "ML&AI Academic Research"
location: "Vancouver, BC"
duration: "Feb 2024 - Apr 2024"
technologies: "Hugging Face, PyTorch, RAG, NLP"
projectImage: "images/works/llm.png"
---
<div style="margin-bottom: 40px;"></div>
<div style="margin-bottom: 40px;"></div>

#### Reference Link:

<div style="margin-bottom: 40px;"></div>

[Reference Link](https://github.com/Raulitoflying/CS7980-llms-political)

<div style="margin-bottom: 40px;"></div>

#### Key Accomplishments:
- Engineered a political stance classifier using RAG and hybrid NLP-graph techniques, achieving 90% accuracy by **fine-tuning** large language
models and designing prompt templates to improve generalization across domains.
- Constructed scalable embedding pipelines with **LangChain**, **pgvector**, and **spaCy-based NLP preprocessing**, aggregating over **70,000+** social media textual records (Twitter, Reddit) to enhance training diversity and robustness.
- Benchmarked open-source and proprietary LLMs **(Claude, Gemini, Mistral, LLaMA)** across **10+** political topics, applying cross-model bias mitigation and visualizing results in **Tableau** to assess fairness.

<div style="margin-bottom: 40px;"></div>

#### Technologies Used:
- **Hugging Face**: For accessing pre-trained models and tokenizers
- **PyTorch**: Deep learning framework for model training
- **RAG (Retrieval-Augmented Generation)**: For enhancing model responses
- **NLP**: Natural Language Processing techniques for text preprocessing
- **LangChain**: For building LLM-powered applications
- **spaCy**: For advanced NLP preprocessing
- **Tableau**: For visualizing results and assessing fairness

This project demonstrates the application of state-of-the-art language models for political stance classification, with a focus on accuracy, fairness, and cross-domain generalization. 