+++
title = "LLM-based Political Stance Classification"
draft = false
technologies = "Hugging Face, PyTorch, RAG, NLP"
projectImage = "images/projects/llm-classification.jpg"
+++

## LLM-based Political Stance Classification

Engineered a political stance classifier using RAG and hybrid NLP-graph techniques, achieving 90% accuracy by fine-tuning large language models.

### Key Features

- Designed prompt templates to improve generalization across domains
- Constructed scalable embedding pipelines with LangChain, pgvector, and spaCy-based NLP preprocessing
- Aggregated over 70,000+ social media textual records (Twitter, Reddit) to enhance training diversity
- Benchmarked open-source and proprietary LLMs (Claude, Gemini, Mistral, LLaMA) across 10+ political topics

### Technologies Used

- **Hugging Face**: For accessing pre-trained models and tokenizers
- **PyTorch**: Deep learning framework for model training
- **RAG (Retrieval-Augmented Generation)**: For enhancing model responses with retrieved information
- **NLP**: Natural Language Processing techniques for text preprocessing
- **LangChain**: For building LLM-powered applications
- **spaCy**: For advanced NLP preprocessing
- **Tableau**: For visualizing results and assessing fairness

This project demonstrates the application of state-of-the-art language models for political stance classification, with a focus on accuracy, fairness, and cross-domain generalization. 