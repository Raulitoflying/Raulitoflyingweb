---
date: 2024-02-20T00:00:00+01:00
draft: false
title: "LLM-based Political Stance Classification"
projectTitle: "LLM-based Political Stance Classification"
company: "Academic Research"
location: "Vancouver, BC"
duration: "Feb 2024 - Apr 2024"
technologies: "Hugging Face, PyTorch, RAG, NLP"
projectImage: "assets/images/works/llm.png"
---
### Reference Link:

Reference Link: [https://github.com/Raulitoflying/CS7980-llms-political](https://github.com/Raulitoflying/CS7980-llms-political)

### Key Accomplishments:

- Designed prompt templates to improve generalization across domains
- Constructed scalable embedding pipelines with LangChain, pgvector, and spaCy-based NLP preprocessing
- Aggregated over 70,000+ social media textual records (Twitter, Reddit) to enhance training diversity
- Benchmarked open-source and proprietary LLMs (Claude, Gemini, Mistral, LLaMA) across 10+ political topics

### Technologies Used:
- **Hugging Face**: For accessing pre-trained models and tokenizers
- **PyTorch**: Deep learning framework for model training
- **RAG (Retrieval-Augmented Generation)**: For enhancing model responses
- **NLP**: Natural Language Processing techniques for text preprocessing
- **LangChain**: For building LLM-powered applications
- **spaCy**: For advanced NLP preprocessing
- **Tableau**: For visualizing results and assessing fairness

This project demonstrates the application of state-of-the-art language models for political stance classification, with a focus on accuracy, fairness, and cross-domain generalization. 